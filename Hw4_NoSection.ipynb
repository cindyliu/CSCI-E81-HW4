{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadi\\Anaconda3\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
      "C:\\Users\\Shadi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import sknn\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import svm\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load data: 0.518s\n",
      "Train data 0: (10000, 3072) 10000\n",
      "Train data 1: (10000, 3072) 10000\n",
      "Train data 2: (10000, 3072) 10000\n",
      "Train data 3: (10000, 3072) 10000\n",
      "Train data 4: (10000, 3072) 10000\n",
      "Test data: (10000, 3072) 10000\n",
      "Merged train data: (50000, 3072) 50000\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    'data_batch_1',\n",
    "    'data_batch_2',\n",
    "    'data_batch_3',\n",
    "    'data_batch_4',\n",
    "    'data_batch_5',\n",
    "    'test_batch'\n",
    "]\n",
    "data = []\n",
    "labels = []\n",
    "start = time.time()\n",
    "for file in files:\n",
    "    with open(file, 'rb') as f:\n",
    "        d = pickle.load(f, encoding='bytes')\n",
    "        if file == 'test_batch':\n",
    "            test_data = d[b'data']\n",
    "            test_labels = d[b'labels']\n",
    "        else:\n",
    "            data.append(d[b'data'])\n",
    "            labels.append(d[b'labels'])\n",
    "end = time.time()\n",
    "print('Time to load data: {:.3f}s'.format(end - start))\n",
    "for i in range(len(data)):\n",
    "    print('Train data {}:'.format(i), data[i].shape, len(labels[i]))\n",
    "print('Test data:', test_data.shape, len(test_labels))\n",
    "\n",
    "merged_data = reduce(lambda a,b: np.vstack((a,b)), data)\n",
    "merged_labels = reduce(lambda a,b: a+b, labels)\n",
    "print('Merged train data:', merged_data.shape, len(merged_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and print out time- this code is taken directly from section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(merged_data) \n",
    "#Train our scaler based on our training data\n",
    "\n",
    "train_data = merged_data[:]\n",
    "train_labels = merged_labels[:]\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "#Apply our scaling to our training and test data, creating a copy of our merged data called 'train_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling all the data so the Neural Network will work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 168.079s\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbgfs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=1)\n",
    "start = time.time()\n",
    "mlp.fit(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Create and train a basic Multi Layer Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.013999999999996"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp.predict(train_data) #Store the predictions for this basic model\n",
    "correct = merged_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "accuracy = (correct == 0).sum() / len(correct)\n",
    "accuracy * 100\n",
    "#This is the accuracy of the base model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our basic MLP model seems to have an accuracy of roughly 30-32% to start- looks like there's a lot of optimization we can do on this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    "\n",
    "The documentation for the Lasagne package was extensively utilized for creating the following Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 7249.084s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svmc = svm.SVC()\n",
    "svmc.fit(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.810000000000002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM at 54.8% accuracy- much higher than the 30.34% of our MLP Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to try varying the size of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(train_labels)\n",
    "#We have 5,000 of each lable in our data\n",
    "\n",
    "bucket = []\n",
    "indices = []\n",
    "for i in range(0,10):\n",
    "    temp = [z for z, x in enumerate(train_labels) if x == i]\n",
    "    indices.append(temp)\n",
    "    bucket.append(indices[i])\n",
    "#This finds all the indexes for each value in our training data, and stores them into the 'bucket' list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = []\n",
    "l1 = []\n",
    "\n",
    "t2 = []\n",
    "l2 = []\n",
    "\n",
    "t3 = []\n",
    "l3 = []\n",
    "#Create our training and label subsets\n",
    "\n",
    "c12 = []\n",
    "c13 = []\n",
    "c23 = []\n",
    "#Create our combined training sets\n",
    "\n",
    "v12 = []\n",
    "v13 = []\n",
    "v23 = []\n",
    "#Create our combined label sets\n",
    "\n",
    "for i in range(0,10):\n",
    "    t1.extend(bucket[i][:1700])\n",
    "    l1.extend(bucket[i][:1700])\n",
    "    \n",
    "    t2.extend(bucket[i][1701:3400])\n",
    "    l2.extend(bucket[i][1701:3400])\n",
    "    \n",
    "    t3.extend(bucket[i][3401:5000])\n",
    "    l3.extend(bucket[i][3401:5000])\n",
    "    #Now we append those index subsets together. This is for our basic sets.\n",
    "    \n",
    "    c12.extend(bucket[i][:3400])\n",
    "    c13.extend(bucket[i][:1700])\n",
    "    c13.extend(bucket[i][3401:5000])\n",
    "    c23.extend(bucket[i][1701:5000])\n",
    "    \n",
    "    v12.extend(bucket[i][:3400])\n",
    "    v13.extend(bucket[i][:1700])\n",
    "    v13.extend(bucket[i][3401:5000])\n",
    "    v23.extend(bucket[i][1701:5000])\n",
    "    #Now for the combined sets\n",
    "\n",
    "t1 = train_data[np.array(t1)]\n",
    "l1 = [train_labels[i] for i in l1]\n",
    "\n",
    "t2 = train_data[np.array(t2)]\n",
    "l2 = [train_labels[i] for i in l2]\n",
    "\n",
    "t3 = train_data[np.array(t3)]\n",
    "l3 = [train_labels[i] for i in l3]\n",
    "#And now we convert them so they're actually lists of values rather than indices\n",
    "#Above is simple sets\n",
    "\n",
    "c12 = train_data[np.array(c12)]\n",
    "v12 = [train_labels[i] for i in v12]\n",
    "\n",
    "c13 = train_data[np.array(c13)]\n",
    "v13 = [train_labels[i] for i in v13]\n",
    "\n",
    "c23 = train_data[np.array(c23)]\n",
    "v23 = [train_labels[i] for i in v23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've split our data into the following sets:\n",
    "\n",
    "T1/T2/T3: Training data, in thirds, of the original set- each containing the same number of each class\n",
    "C12/C13/C23: Combined versions of the above three sets. We've already used ALL the data in a run, so there's no point to C123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 61.733s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp.fit(t1, l1)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Basic MLP model with the first test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.350000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 61.143s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp.fit(t2, l2)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Basic MLP model with the second test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.039999999999999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 57.365s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp.fit(t3, l3)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Basic MLP model with the third test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.089999999999996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 116.076s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp.fit(c12, v12)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Basic MLP model with the first combined set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.210000000000001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 116.821s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp.fit(c13, v13)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Basic MLP model with the second combined set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.360000000000003"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 113.407s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp.fit(c23, v23)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Basic MLP model with the final combined set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.160000000000004"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finishes our comparison of the MLP classifier- next we have to compare our SVM classifier. Generally speaking the classifiers took about 1-2 minutes to build- looks like my computer runs at almost 1 minute/17,000 records for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 908.899s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svmc.fit(t1, l1)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.919999999999995"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#First set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 893.248s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svmc.fit(t2, l2)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.710000000000001"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Second set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 807.029s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svmc.fit(t3, l3)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.669999999999995"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Third set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svmc.fit(c12, v12)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#First Combo set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svmc.fit(c13, v13)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Second Combo set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svmc.fit(c23, v23)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Last Combo set"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
