{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import sknn\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import svm\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load data: 0.517s\n",
      "Train data 0: (10000, 3072) 10000\n",
      "Train data 1: (10000, 3072) 10000\n",
      "Train data 2: (10000, 3072) 10000\n",
      "Train data 3: (10000, 3072) 10000\n",
      "Train data 4: (10000, 3072) 10000\n",
      "Test data: (10000, 3072) 10000\n",
      "Merged train data: (50000, 3072) 50000\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    'data_batch_1',\n",
    "    'data_batch_2',\n",
    "    'data_batch_3',\n",
    "    'data_batch_4',\n",
    "    'data_batch_5',\n",
    "    'test_batch'\n",
    "]\n",
    "data = []\n",
    "labels = []\n",
    "start = time.time()\n",
    "for file in files:\n",
    "    with open(file, 'rb') as f:\n",
    "        d = pickle.load(f, encoding='bytes')\n",
    "        if file == 'test_batch':\n",
    "            test_data = d[b'data']\n",
    "            test_labels = d[b'labels']\n",
    "        else:\n",
    "            data.append(d[b'data'])\n",
    "            labels.append(d[b'labels'])\n",
    "end = time.time()\n",
    "print('Time to load data: {:.3f}s'.format(end - start))\n",
    "for i in range(len(data)):\n",
    "    print('Train data {}:'.format(i), data[i].shape, len(labels[i]))\n",
    "print('Test data:', test_data.shape, len(test_labels))\n",
    "\n",
    "merged_data = reduce(lambda a,b: np.vstack((a,b)), data)\n",
    "merged_labels = reduce(lambda a,b: a+b, labels)\n",
    "print('Merged train data:', merged_data.shape, len(merged_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and print out time- this code is taken directly from section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(merged_data) \n",
    "#Train our scaler based on our training data\n",
    "\n",
    "train_data = merged_data[:]\n",
    "train_labels = merged_labels[:]\n",
    "orig_data = test_data[:]\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "#Apply our scaling to our training and test data, creating a copy of our merged data called 'train_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling all the data so the Neural Network will work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 168.079s\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbgfs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=1)\n",
    "start = time.time()\n",
    "mlp.fit(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Create and train a basic Multi Layer Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.013999999999996"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp.predict(train_data) #Store the predictions for this basic model\n",
    "correct = merged_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "accuracy = (correct == 0).sum() / len(correct)\n",
    "accuracy * 100\n",
    "#This is the accuracy of the base model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our basic MLP model seems to have an accuracy of roughly 30-32% to start- looks like there's a lot of optimization we can do on this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    "\n",
    "The documentation for the Lasagne package was extensively utilized for creating the following Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 7249.084s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svmc = svm.SVC()\n",
    "svmfull = svm.SVC()\n",
    "svmfull.fit(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.810000000000002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svmfull.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM at 54.8% accuracy- much higher than the 30.34% of our MLP Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 32, 32, 3) (50000,)\n",
      "Test set (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "img_size = 32\n",
    "num_labels = 10\n",
    "num_channels = 3\n",
    "\n",
    "train_labels_np = np.array(merged_labels)\n",
    "test_labels_np = np.array(test_labels)\n",
    "\n",
    "# modified section's reformatting function a bit so it doesn't use global var\n",
    "# although i suppose using the global var is not the worst thing in the world\n",
    "def reformat(dataset, labels, img_size, num_channels=1):\n",
    "    dataset = dataset.reshape((-1, img_size, img_size, num_channels)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "cnn_train_data, cnn_train_labels = reformat(train_data, train_labels_np, img_size, num_channels)\n",
    "cnn_test_data, test_labels_np_onehot = reformat(test_data, test_labels_np, img_size, num_channels)\n",
    "print('Training set', cnn_train_data.shape, train_labels_np.shape)\n",
    "print('Test set', cnn_test_data.shape, test_labels_np_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 6s - loss: 3.5210 - acc: 0.0905     \n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 6s - loss: 2.3042 - acc: 0.0917     \n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 6s - loss: 2.2538 - acc: 0.1137     \n",
      " 9984/10000 [============================>.] - ETA: 0s\n",
      "\n",
      "Test set accuracy: 14.61%\n",
      "Time to build: 19.190s\n"
     ]
    }
   ],
   "source": [
    "# Using the Keras way to translate the labels to one-hot format rather than the section's reformatting method\n",
    "Y_train = np_utils.to_categorical(train_labels_np, num_labels)\n",
    "\n",
    "# initialize model and add layers\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(3, 3, 3, input_shape=cnn_train_data.shape[1:], name='name'))\n",
    "model.add(Flatten())  # need to flatten to get correct input dimensions (2-d) for dense layer\n",
    "model.add(Dense(num_labels))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "start = time.time()\n",
    "model.fit(x=cnn_train_data, y=cnn_train_labels, nb_epoch=3, batch_size=256)\n",
    "end = time.time()\n",
    "predictions = model.predict_classes(cnn_test_data, batch_size=256)\n",
    "correct = (predictions[:,None] == test_labels_np[:,None]).astype(int)\n",
    "print('\\n\\nTest set accuracy: {:.2f}%'.format((100.*sum(correct)/len(correct))[0]))\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the CNN is struggling with accuracy- this is likely due to a normalization issue, but I'm not sure where the mistake is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to try varying the size of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(train_labels)\n",
    "#We have 5,000 of each lable in our data\n",
    "\n",
    "bucket = []\n",
    "indices = []\n",
    "for i in range(0,10):\n",
    "    temp = [z for z, x in enumerate(train_labels) if x == i]\n",
    "    indices.append(temp)\n",
    "    bucket.append(indices[i])\n",
    "#This finds all the indexes for each value in our training data, and stores them into the 'bucket' list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = []\n",
    "l1 = []\n",
    "\n",
    "t2 = []\n",
    "l2 = []\n",
    "\n",
    "t3 = []\n",
    "l3 = []\n",
    "#Create our training and label subsets\n",
    "\n",
    "c12 = []\n",
    "c13 = []\n",
    "c23 = []\n",
    "#Create our combined training sets\n",
    "\n",
    "v12 = []\n",
    "v13 = []\n",
    "v23 = []\n",
    "#Create our combined label sets\n",
    "\n",
    "for i in range(0,10):\n",
    "    t1.extend(bucket[i][:1700])\n",
    "    l1.extend(bucket[i][:1700])\n",
    "    \n",
    "    t2.extend(bucket[i][1701:3400])\n",
    "    l2.extend(bucket[i][1701:3400])\n",
    "    \n",
    "    t3.extend(bucket[i][3401:5000])\n",
    "    l3.extend(bucket[i][3401:5000])\n",
    "    #Now we append those index subsets together. This is for our basic sets.\n",
    "    \n",
    "    c12.extend(bucket[i][:3400])\n",
    "    c13.extend(bucket[i][:1700])\n",
    "    c13.extend(bucket[i][3401:5000])\n",
    "    c23.extend(bucket[i][1701:5000])\n",
    "    \n",
    "    v12.extend(bucket[i][:3400])\n",
    "    v13.extend(bucket[i][:1700])\n",
    "    v13.extend(bucket[i][3401:5000])\n",
    "    v23.extend(bucket[i][1701:5000])\n",
    "    #Now for the combined sets\n",
    "\n",
    "t1 = train_data[np.array(t1)]\n",
    "l1 = [train_labels[i] for i in l1]\n",
    "\n",
    "t2 = train_data[np.array(t2)]\n",
    "l2 = [train_labels[i] for i in l2]\n",
    "\n",
    "t3 = train_data[np.array(t3)]\n",
    "l3 = [train_labels[i] for i in l3]\n",
    "#And now we convert them so they're actually lists of values rather than indices\n",
    "#Above is simple sets\n",
    "\n",
    "c12 = train_data[np.array(c12)]\n",
    "v12 = [train_labels[i] for i in v12]\n",
    "\n",
    "c13 = train_data[np.array(c13)]\n",
    "v13 = [train_labels[i] for i in v13]\n",
    "\n",
    "c23 = train_data[np.array(c23)]\n",
    "v23 = [train_labels[i] for i in v23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've split our data into the following sets:\n",
    "\n",
    "T1/T2/T3: Training data, in thirds, of the original set- each containing the same number of each class\n",
    "C12/C13/C23: Combined versions of the above three sets. We've already used ALL the data in a run, so there's no point to C123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 61.733s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp.fit(t1, l1)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Basic MLP model with the first test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.350000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 116.076s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp.fit(c12, v12)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))\n",
    "#Basic MLP model with the first combined set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.210000000000001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = mlp.predict(test_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finishes our comparison of the MLP classifier- next we have to compare our SVM classifier. Generally speaking the classifiers took about 1-2 minutes to build- looks like my computer runs at almost 1 minute/17,000 records for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 908.899s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svmc.fit(t1, l1)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.919999999999995"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#First set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build: 3382.673s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svmc.fit(c12, v12)\n",
    "end = time.time()\n",
    "print('Time to build: {:.3f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.810000000000002"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svmc.predict(test_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#First Combo set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM algorithms can take up to an hour for the combined data sets. With that said, their accuracy is quite high- at 52-53% they outperform the unoptimized MLP handily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll modify our test data, then rerun the algorithms on it and see how our classifiers hold up on this new modified test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "distort_data = orig_data[:]\n",
    "for i in range(0, len(distort_data)):\n",
    "    distort_data[i][:31] = round(np.mean(distort_data))\n",
    "distort_data = scaler.transform(distort_data)\n",
    "#This distortion replaces the first 32 numbers with the mean- essentially averaging out the top row\n",
    "#The data is then rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.370000000000001"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(train_data, train_labels)\n",
    "#Refit the full model onto this data\n",
    "\n",
    "test_pred = mlp.predict(distort_data)\n",
    "correct = test_labels - test_pred #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the distorted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some accuracy loss- by a few percentage points, but still better than random (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = svmfull.predict(distort_data)\n",
    "correct = test_labels - predictions #If the numbers are the same, they'll be 0, otherwise- any other number\n",
    "test_accuracy = (correct == 0).sum() / len(correct)\n",
    "test_accuracy * 100\n",
    "#Accuracy of the base model on the distorted data"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
